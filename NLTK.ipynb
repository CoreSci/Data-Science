{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c021b-9f82-4fd4-896b-d6520b232aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Natural Language Toolkit (NLTK) is a powerful library for working with human language data. Here's a simple example of using NLTK in Python for basic text processing and tokenization\n",
    "#This example demonstrates tokenization using word_tokenize and removal of common English stopwords.\n",
    "#Make sure you have NLTK installed (pip install nltk) and have downloaded the necessary data using nltk.download() before running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec9117c-4743-4bb0-8a4c-0a2bebe78646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c4a6c7-b54f-431c-bde7-4c6f05245a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35180bbe-2336-4f41-bede-191b55e4aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = \"NLTK is a powerful library for natural language processing in Python.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7106299-0881-4c05-8dae-39753ab906a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1750ed2c-5bf3-4e7f-89f5-bf266ae6b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653ba22a-4cb3-4197-94cc-a417e7278e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'natural', 'language', 'processing', 'in', 'Python', '.']\n",
      "Filtered words: ['NLTK', 'powerful', 'library', 'natural', 'language', 'processing', 'Python', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original words:\", words)\n",
    "print(\"Filtered words:\", filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82392eb3-53df-40a3-880c-0334a0cdf0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
